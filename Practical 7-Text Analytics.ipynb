{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text= \"\"\" India is my country and all Indians are my brothers\n",
    "and sisters. I love my country and I am proud of its\n",
    "rich and varied heritage. I shall always strive to be\n",
    "worthy of it. I shall give respect to my parents,\n",
    "teachers and elders and treat everyone with\n",
    "courtesy. To my country and my people, I pledge\n",
    "my devotion. In their well being and prosperity\n",
    "alone, lies my happiness.\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Tokenization using Python’s split() function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#word tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split at space\n",
    "#text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' India is my country and all Indians are my brothers\\nand sisters. I love my country and I am proud of its\\nrich and varied heritage. I shall always strive to be\\nworthy of it. I shall give respect to my parents',\n",
       " '\\nteachers and elders and treat everyone with\\ncourtesy. To my country and my people',\n",
       " ' I pledge\\nmy devotion. In their well being and prosperity\\nalone',\n",
       " ' lies my happiness.']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##split at comma\n",
    "text.split(',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' India is my country and all Indians are my brothers\\nand sisters',\n",
       " ' I love my country and I am proud of its\\nrich and varied heritage',\n",
       " ' I shall always strive to be\\nworthy of it',\n",
       " ' I shall give respect to my parents,\\nteachers and elders and treat everyone with\\ncourtesy',\n",
       " ' To my country and my people, I pledge\\nmy devotion',\n",
       " ' In their well being and prosperity\\nalone, lies my happiness',\n",
       " '']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#split at full stop\n",
    "text.split('.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' # India_  ',\n",
       " '  is  %% my country and all Indians are my brothers\\nand sisters. I love my country and I am proud of its\\nrich and varied heritage. I shall %% always strive to be\\nworthy of it. I shall give respect to my parents,\\nteachers and elders and treat everyone with\\ncourtesy.To my country and my people, I pledge\\nmy devotion. In their well being and prosperity\\nalone, lies my happiness. ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text=\"\"\" # India_  @  is  %% my country and all Indians are my brothers\n",
    "and sisters. I love my country and I am proud of its\n",
    "rich and varied heritage. I shall %% always strive to be\n",
    "worthy of it. I shall give respect to my parents,\n",
    "teachers and elders and treat everyone with\n",
    "courtesy.To my country and my people, I pledge\n",
    "my devotion. In their well being and prosperity\n",
    "alone, lies my happiness. \"\"\"\n",
    "\n",
    "#split at '@' symbol\n",
    "text.split('@')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Tokenization using Regular Expressions (RegEx)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "text=\"\"\" # India_  @  is  %% my country and all Indians are my brothers\n",
    "and sisters. I love my country and I am proud of its\n",
    "rich and varied heritage. I shall %% always strive to be\n",
    "worthy of it. I shall give respect to my parents,\n",
    "teachers and elders and treat everyone with\n",
    "courtesy.To my country and my people, I pledge\n",
    "my devotion. In their well being and prosperity\n",
    "alone, lies my happiness. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['%%', '%%']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#- [\\%%]+ signals that the code should find all the %% characters until any other character is encountered.\n",
    "tokens=re.findall(\"[\\%%]+\",text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['@']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#-[\\%%]+ signals that the code should find all the %% characters until any other character is encountered.\n",
    "tokens=re.findall(\"[\\@]+\",text)\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-[\\w’]+ signals that the code should find all the alphanumeric characters until any other character is encountered\n",
    "#- The “\\w” represents “any word character” which usually means alphanumeric (letters, numbers) and underscore (_). ‘+’ means any number of times\n",
    "tokens=re.findall(\"[\\w]+\",text)\n",
    "#tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Word Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' India is my country and all Indians are my brothers\\nand sisters',\n",
       " ' I love my country and I am proud of its\\nrich and varied heritage',\n",
       " ' I shall always strive to be\\nworthy of it',\n",
       " ' I shall give respect to my parents',\n",
       " '\\nteachers and elders and treat everyone with\\ncourtesy',\n",
       " '',\n",
       " ' To my country and my people, I pledge\\nmy devotion',\n",
       " ' In their well',\n",
       " ' being and prosperity\\nalone, lies my happiness',\n",
       " '  ']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text= \"\"\" India is my country and all Indians are my brothers\n",
    "and sisters! I love my country and I am proud of its\n",
    "rich and varied heritage. I shall always strive to be\n",
    "worthy of it. I shall give respect to my parents?\n",
    "teachers and elders and treat everyone with\n",
    "courtesy?? To my country and my people, I pledge\n",
    "my devotion. In their well/ being and prosperity\n",
    "alone, lies my happiness.  \"\"\"\n",
    "\n",
    "#split the text into sentences by passing a pattern into it.\n",
    "\n",
    "\n",
    "sentence=re.compile('[.!?/]').split(text)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Tokenization using NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text=\"\"\" India is my country and all Indians are my brothers\n",
    "and sisters. I love my country and I am proud of its\n",
    "rich and varied heritage. I shall always strive to be\n",
    "worthy of it. I shall give respect to my parents,\n",
    "teachers and elders and treat everyone with\n",
    "courtesy. To my country and my people, I pledge\n",
    "my devotion. In their well being and prosperity\n",
    "alone, lies my happiness. \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "#word_tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[' India is my country and all Indians are my brothers\\nand sisters.',\n",
       " 'I love my country and I am proud of its\\nrich and varied heritage.',\n",
       " 'I shall always strive to be\\nworthy of it.',\n",
       " 'I shall give respect to my parents,\\nteachers and elders and treat everyone with\\ncourtesy.',\n",
       " 'To my country and my people, I pledge\\nmy devotion.',\n",
       " 'In their well being and prosperity\\nalone, lies my happiness.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tokenize(text)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POS Tagging"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentence=\"\"\"ndia is my country and all Indians are my brothers and sisters. I love my country and I am proud of its rich and varied heritage. I shall always strive to be worthy of it. I shall give respect to my parents, teachers and elders and treat everyone with courtesy \"\"\"\n",
    "tokens=nltk.word_tokenize(sentence)\n",
    "tagged=nltk.pos_tag(tokens)\n",
    "#tagged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tag import tnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import indian\n",
    "train_data=indian.tagged_sents('hindi.pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tnt_pos_tagger=tnt.TnT()\n",
    "tnt_pos_tagger.train(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('भारत', 'NNP'), ('हमारा', 'Unk'), ('देश', 'NN'), ('है।', 'Unk'), ('हम', 'PRP'), ('सब', 'INTF'), ('भारतवासी', 'Unk'), ('भाई-बहन', 'Unk'), ('हैं।', 'Unk'), ('हमें', 'PRP'), ('अपना', 'PRP'), ('देश', 'NN'), ('प्राणों', 'Unk'), ('से', 'PREP'), ('भी', 'RP'), ('प्यारा', 'Unk'), ('है।', 'Unk'), ('इसकी', 'PRP'), ('समृद्धि', 'Unk'), ('और', 'CC'), ('विविध', 'Unk'), ('संस्कृति', 'Unk'), ('पर', 'PREP'), ('हमें', 'PRP'), ('गर्व', 'Unk'), ('है।', 'Unk'), ('हम', 'PRP'), ('इसके', 'PRP'), ('सुयोग्य', 'Unk'), ('अधिकारी', 'NN'), ('बनने', 'Unk'), ('का', 'PREP'), ('प्रयन्त', 'Unk'), ('सदा', 'Unk'), ('करते', 'VJJ'), ('रहेंगे।', 'Unk'), ('हम', 'PRP'), ('अपने', 'PRP'), ('माता-पिता', 'Unk'), (',', 'PUNC'), ('शिक्षकों', 'Unk'), ('और', 'CC'), ('गुरुजनों', 'Unk'), ('का', 'PREP'), ('आदर', 'Unk'), ('करेंगे', 'VFM'), ('और', 'CC'), ('सबके', 'NN'), ('साथ', 'PREP'), ('शिष्ठता', 'Unk'), ('का', 'PREP'), ('व्यवहार', 'Unk'), ('करेंगे।', 'Unk'), ('हम', 'PRP'), ('अपने', 'PRP'), ('देश', 'NN'), ('और', 'CC'), ('देशवासियों', 'Unk'), ('के', 'PREP'), ('प्रति', 'JJ'), ('वफ़ादार', 'Unk'), ('रहने', 'VNN'), ('की', 'PREP'), ('प्रतिज्ञा', 'Unk'), ('करते', 'VJJ'), ('हैं।', 'Unk'), ('उनके', 'PRP'), ('कल्याण', 'NN'), ('और', 'CC'), ('समृद्धि', 'Unk'), ('में', 'PREP'), ('ही', 'RP'), ('हमारा', 'Unk'), ('सुख', 'Unk'), ('निहित', 'Unk'), ('है।', 'Unk'), ('जय', 'Unk'), ('हिन्द।', 'Unk')]\n"
     ]
    }
   ],
   "source": [
    "words=\" भारत हमारा देश है। हम सब भारतवासी भाई-बहन हैं। हमें अपना देश प्राणों से भी प्यारा है। इसकी समृद्धि और विविध संस्कृति पर हमें गर्व है।  हम इसके सुयोग्य अधिकारी बनने का प्रयन्त सदा करते रहेंगे। हम अपने माता-पिता, शिक्षकों और गुरुजनों का आदर करेंगे और सबके साथ शिष्ठता का व्यवहार करेंगे। हम अपने देश और देशवासियों के प्रति वफ़ादार रहने की प्रतिज्ञा करते हैं। उनके कल्याण और समृद्धि में ही हमारा सुख निहित है। जय हिन्द। \"\n",
    "tagged_words=(tnt_pos_tagger.tag(nltk.word_tokenize(words)))\n",
    "print(tagged_words)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop words removal"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['India', 'country', 'Indians', 'brothers', 'sisters', '.', 'love', 'country', 'proud', 'rich', 'varied', 'heritage', '.', 'shall', 'always', 'strive', 'worthy', '.', 'shall', 'give', 'respect', 'parents', ',', 'teachers', 'elders', 'treat', 'everyone', 'courtesy', '.', 'country', 'people', ',', 'pledge', 'devotion', '.', 'well', 'prosperity', 'alone', ',', 'lies', 'happiness']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "example=\"\"\" India is my country and all Indians are my brothers and sisters. I love my country and I am proud of its rich and varied heritage. I shall always strive to be worthy of it. I shall give respect to my parents, teachers and elders and treat everyone with courtesy. To my country and my people, I pledge my devotion. In their well being and prosperity alone, lies my happiness \"\"\"\n",
    "stop_words=set(stopwords.words('english'))\n",
    "word_tokens=word_tokenize(example)\n",
    "filtered_sentence=[j for j in word_tokens if not j.lower() in stop_words]\n",
    "print(filtered_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['My', 'name', 'Aishwarya', '.', 'I', 'pursuing', 'Bachelor', 'Computer', 'Engineering', 'AISSMS', \"'s\", 'Institute', 'Informaion', 'Technology']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "li=[]\n",
    "ex=\"\"\" My name is Aishwarya .\n",
    "        I am pursuing my Bachelor of Computer Engineering from AISSMS's Institute of Informaion Technology\"\"\"\n",
    "stop_words=set(stopwords.words('english'))\n",
    "word_tokens=word_tokenize(ex)\n",
    "for i in word_tokens:\n",
    "    if i not in stop_words:\n",
    "        li.append(i)\n",
    "        \n",
    "print(li)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relatively  :  rel\n",
      "relate  :  relat\n",
      "realize  :  realiz\n",
      "related  :  relat\n",
      "relative  :  rel\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "ps = PorterStemmer()\n",
    "words = [\"Relatively\", \"relate\", \"realize\", \"related\", \"relative\"]\n",
    " \n",
    "for w in words:\n",
    "    print(w, \" : \", ps.stem(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "books : book\n",
      "insertion : insertion\n",
      "Bad : Bad\n"
     ]
    }
   ],
   "source": [
    "# import these modules\n",
    "from nltk.stem import WordNetLemmatizer\n",
    " \n",
    "lemmatizer = WordNetLemmatizer()\n",
    " \n",
    "print(\"books :\", lemmatizer.lemmatize(\"books\"))\n",
    "print(\"insertion :\", lemmatizer.lemmatize(\"insertion\"))\n",
    " \n",
    "# a denotes adjective in \"pos\"\n",
    "print(\"Bad :\", lemmatizer.lemmatize(\"Bad\", pos =\"a\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
